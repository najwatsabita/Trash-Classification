name: ML Model CI/CD

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  train:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install torch torchvision pytorch-lightning fastapi uvicorn pillow wandb google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client gdown
        
    - name: Debug Google Drive ID
      run: |
        echo "Using Google Drive Folder ID: ${{ secrets.DATASET_FOLDER_ID }}"
        
    - name: Download and verify dataset
      run: |
        # Create directories
        mkdir -p dataset
        mkdir -p ~/.cache/gdown
        
        # Create cookies from secret
        echo "${{ secrets.GDRIVE_COOKIES }}" > ~/.cache/gdown/cookies.txt
        
        # Download with cookies
        gdown "https://drive.google.com/drive/folders/${{ secrets.DATASET_FOLDER_ID }}" \
          --folder \
          -O dataset \
          --remaining-ok \
          --continue
        
        # Debug information
        echo "=== Current Directory ==="
        pwd
        
        echo "=== Dataset Directory Location ==="
        ls -la
        
        echo "=== Dataset Contents ==="
        ls -R dataset/
        
        echo "=== Directory Tree ==="
        tree dataset/ || true
        
    - name: Configure Wandb
      env:
        WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
      run: |
        wandb login $WANDB_API_KEY
        
    - name: Create checkpoint directory
      run: |
        mkdir -p checkpoint
        mkdir -p logs
        
    - name: Train model
      env:
        WANDB_PROJECT: trash-classification
      run: |
        echo "=== Pre-training Dataset Check ==="
        ls -R dataset/
        python train.py
